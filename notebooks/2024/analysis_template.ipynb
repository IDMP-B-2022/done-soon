{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "from rich.progress import track\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MaxAbsScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = \"ablation-problem-class\"\n",
    "ANALYSIS_BASE = \"./analysis/paper-data/\"\n",
    "INCLUDE_EWMA = False\n",
    "INCLUDE_GRADIENTS = False\n",
    "\n",
    "CROSS_VALIDATIONS_PATH = f\"./cross-validations-{EXPERIMENT_NAME}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dataframe_for_current_experiment(data_flattened):\n",
    "    df = data_flattened.loc[(slice(None), slice(None), INCLUDE_GRADIENTS, INCLUDE_EWMA), :]\n",
    "    df.index = df.index.droplevel([2, 3])\n",
    "    df = df.sort_values(by=['percentage', 'model'])\n",
    "\n",
    "    def float_or_list_to_tuple(x):\n",
    "        if isinstance(x, list):\n",
    "            return tuple(x)\n",
    "        return x\n",
    "\n",
    "    df[\"hidden_layer_sizes\"] = df['hidden_layer_sizes'].apply(float_or_list_to_tuple)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_files(cross_validations_path, seed):\n",
    "    \"\"\"\n",
    "    Parse files and use pd.json_normalize to flatten the json.\n",
    "    \"\"\"\n",
    "    files = Path(ANALYSIS_BASE).joinpath(f\"{cross_validations_path}-{seed}\").glob(\"**/*.json\")\n",
    "    results = pd.DataFrame()\n",
    "    files = list(files)\n",
    "\n",
    "    for file in track(\n",
    "        files,\n",
    "        description=\"Loading hyperparameters and \"\n",
    "        \"performance data from file to DataFrame\",\n",
    "    ):\n",
    "        with open(file) as f:\n",
    "            data = json.load(f)\n",
    "            original_target = data[\"original_target\"]\n",
    "            original_dict = json.loads(Path(original_target).read_text())\n",
    "\n",
    "            f1_scores = pd.json_normalize(data, \"f1_scores\")\n",
    "            normalized_data = pd.json_normalize(original_dict)\n",
    "            normalized_data = pd.concat(\n",
    "                [normalized_data] * len(f1_scores), ignore_index=True\n",
    "            )\n",
    "            normalized_data[\"metrics.f1_score\"] = f1_scores\n",
    "            normalized_data[\"paths.model_path\"] = data[\"model_path\"]\n",
    "            results = pd.concat([results, normalized_data])\n",
    "\n",
    "    results = results.set_index(\n",
    "        [\"percentage\", \"model\", \"use_gradient\", \"use_ewma\"]\n",
    "    )\n",
    "    results.columns = pd.MultiIndex.from_arrays(\n",
    "        zip(*results.columns.str.split(\".\", expand=True))\n",
    "    )\n",
    "    results = results.sort_index(axis=1)\n",
    "    results = results.drop(columns=['k_fold', 'preprocessing'])\n",
    "    results = results.droplevel(0, axis=1)\n",
    "\n",
    "    results = filter_dataframe_for_current_experiment(results)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_best_hyperparameters_from_k_folds(k_folds_data, percentages=None):\n",
    "\n",
    "    if percentages is None:\n",
    "        PERCENTAGES = [1, 5, 10, 15, 20]\n",
    "        \n",
    "    MODELS = ['RF', 'AdaBoost', 'DUM']\n",
    "    FILTER_MODELS = True\n",
    "\n",
    "    # This is a bit hacky, but I add model_path here because its only always the same\n",
    "    # so it doesn't have effect on the groupby.\n",
    "    # Would be better to `df.merge` though.\n",
    "    group = k_folds_data.groupby(['percentage', 'model', 'C', 'hidden_layer_sizes', 'kernel', 'learning_rate', 'max_depth', 'n_estimators', 'alpha', 'model_path'], dropna=False)\n",
    "    summary = group['f1_score'].agg(['mean', 'std'])\n",
    "\n",
    "    idx = summary.groupby(['percentage', 'model']).idxmax()\n",
    "\n",
    "    best_hyperparams = summary.loc[idx['mean'], :]\n",
    "\n",
    "    best_models_per_percentage_and_type = best_hyperparams[best_hyperparams.index.get_level_values('percentage').isin(PERCENTAGES)]\n",
    "    if FILTER_MODELS:\n",
    "        best_models_per_percentage_and_type =  best_models_per_percentage_and_type[best_models_per_percentage_and_type.index.get_level_values('model').isin(MODELS)]\n",
    "    return best_models_per_percentage_and_type\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_classifiers_from_best_models(best_models_per_percentage_and_type):\n",
    "    classifiers = {}\n",
    "    for _, row in best_models_per_percentage_and_type.reset_index().iterrows():\n",
    "        \n",
    "        with open(row['model_path'], 'rb') as f:\n",
    "            instantiated_model = pickle.load(f)\n",
    "        classifiers[(row['percentage'], row['model'])] = instantiated_model\n",
    "    return classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "203b779e6f984884a9d53a003427a788",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "335bc58c3c5744a0b1a37694d745a1f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa754f0816b74ee9a68570f22834f9e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d844e2c1b1244ec99feb544259282e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "477efcb2381342bfbd64de7835ef1f77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4e37212e4ba4ee28659a8debcbc3cd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54daec3e6592426fb6142335fb9f978c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23bc2a631f354a61b13de89c2a51f2e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1ef986fb0cf461c90ca012ed8a7ea6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cba8bfb7957749d3b396e21c2cc31201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_for_all_seeds = []\n",
    "for i in range(1,11):\n",
    "\n",
    "    current_seed = {\n",
    "        'seed': i\n",
    "    }\n",
    "\n",
    "    data = parse_files(Path(CROSS_VALIDATIONS_PATH), seed=i)\n",
    "    current_seed['k_fold'] = data\n",
    "    \n",
    "    current_seed['best_models'] = pick_best_hyperparameters_from_k_folds(data)\n",
    "    current_seed['classifiers'] = load_classifiers_from_best_models(current_seed['best_models'])\n",
    "\n",
    "    TEST_DATASET_PATH = Path(f'./analysis/paper-data/{EXPERIMENT_NAME}.pkl_test.pkl')\n",
    "    with open(TEST_DATASET_PATH, 'rb') as f:\n",
    "        TEST_DATASET = pickle.load(f)\n",
    "    TRAIN_DATASET_PATH = Path('./analysis/paper-data/{EXPERIMENT_NAME}.pkl_train.pkl')\n",
    "    with open(TRAIN_DATASET_PATH, 'rb') as f:\n",
    "        TRAIN_DATASET = pickle.load(f)\n",
    "\n",
    "    current_seed['train_data'] = TRAIN_DATASET\n",
    "    current_seed['test_data'] = TEST_DATASET\n",
    "    \n",
    "    data_for_all_seeds += [current_seed]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_seed_data_into_single_dataframe_opinionated(total_data):\n",
    "    for seed in total_data:\n",
    "        print(seed['best_models'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(dataframe, scaler=None):\n",
    "    result, mzn = dataframe.drop(columns=['mzn', 'dzn'], axis=1), dataframe['mzn']\n",
    "\n",
    "    result = result.drop(columns=result.columns[result.columns.str.contains('ewma|gradient')], axis=1)\n",
    "\n",
    "    if scaler is None:\n",
    "        result = result.drop(result.columns[result.nunique() == 1], axis=1)\n",
    "        scaler = MaxAbsScaler().fit(result)\n",
    "    else:\n",
    "        # Drop constant columns except those in scaler.feature_names_in_\n",
    "        constant_columns = result.columns[result.nunique() == 1]\n",
    "        features_in = scaler.feature_names_in_\n",
    "        columns_to_drop = constant_columns.difference(features_in)\n",
    "        result = result.drop(columns=columns_to_drop, axis=1)\n",
    "        \n",
    "        \n",
    "    result = pd.DataFrame(scaler.transform(result), columns=result.columns, index=result.index)\n",
    "\n",
    "    result['mzn'] = mzn\n",
    "\n",
    "    return result, scaler\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now here we can split off: <insert your analysis here>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
