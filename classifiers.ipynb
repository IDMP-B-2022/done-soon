{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import json\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16814it [04:31, 62.00it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14498, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base = \"data/done-soon/temp/problem_output/\"\n",
    "all_normal_files = glob(\"data/done-soon/temp/problem_output/*NORMAL.json\")\n",
    "df = pd.DataFrame()\n",
    "data = []\n",
    "\n",
    "num_without_search_time = 0\n",
    "for i, normal in tqdm(enumerate(all_normal_files)):\n",
    "    mzn = normal[normal.find(\"MZN-\")+4:normal.find(\"-DZN\")] + \".mzn\"\n",
    "    dzn = normal[normal.find(\"DZN-\")+4:normal.find(\"-OUTPUT\")] + \".dzn\"\n",
    "\n",
    "    stats = Path(f\"{normal[:-12]}-STATS.json\")\n",
    "    if stats.exists():\n",
    "        with open(normal, 'r') as normal_output, open(f\"{normal[:-12]}-STATS.json\", 'r') as stats_output:\n",
    "            line = normal_output.readline()\n",
    "            if line: # don't read json from empty output\n",
    "                normal_time = json.loads(line).get('time')\n",
    "                stats_all_lines = [json.loads(line).get('statistics') for line in stats_output.readlines()]\n",
    "                stats = stats_all_lines[-1]\n",
    "\n",
    "                if normal_time and stats:\n",
    "                    if \"search_time\" not in stats.keys():\n",
    "                        num_without_search_time += 1\n",
    "                    else:\n",
    "                        data.append({\n",
    "                            'normal_time': normal_time * 0.001,\n",
    "                            'stat_time': stats['search_time'],\n",
    "                            'problem': normal,\n",
    "                            'statistics': stats_all_lines,\n",
    "                            'mzn': mzn,\n",
    "                            'dzn': dzn\n",
    "                        })\n",
    "                        \n",
    "df = pd.DataFrame(data)\n",
    "all_data = df\n",
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(df):\n",
    "    del df[\"decision_level_sat\"]\n",
    "    del df[\"ewma_decision_level_mip\"]\n",
    "    del df[\"decision_level_mip\"]\n",
    "#     del df[\"best_objective\"]\n",
    "#     df[\"unassnVar\"]   = (2**df['vars']) - df['opennodes']\n",
    "#     df[\"fracFailUnassn\"]     = df['conflicts'] / df['unassnVar']         # num failures/ num open nodes\n",
    "    df[\"fracOpenVisit\"]  = (df['vars'] - df['opennodes']) / df['opennodes']       # ratio of open nodes to visited nodes (how much of soln space explored)\n",
    "    df[\"fracBoolVars\"]     = df['boolVars'] / df['vars']                 # num bools / total num of vars\n",
    "    df[\"fracPropVars\"]     = df['propagations'] / df['vars']        # num propagations/ total num of vars\n",
    "#     df[\"frac_unassigned\"] = df['unassnVar'] / df['vars']  # current assignments/ total vars\n",
    "    df[\"fracLongClauses\"] = df['long'] + df['bin'] + df['tern']         # fraction of learnt clauses that have more than 3 literals\n",
    "    df[\"freqBackjumps\"]  = df['back_jumps']/df['search_time']\n",
    "    return df\n",
    "\n",
    "\n",
    "def gradients(df_prev, df_curr):\n",
    "    keys=['conflicts','ewma_conflicts','decisions','search_iterations','opennodes','ewma_opennodes',\n",
    "          'vars','back_jumps','ewma_back_jumps','solutions','total_time','search_time','intVars',\n",
    "          'propagations','sat_propagations','ewma_propagations','propagators','boolVars','learnt',\n",
    "          'bin','tern','long','peak_depth','decision_level_engine','ewma_decision_level_engine',\n",
    "          'decision_level_treesize','clause_mem','prop_mem','ewma_best_objective',\n",
    "          'fracOpenVisit','fracBoolVars','fracPropVars','freqBackjumps', 'best_objective']\n",
    "    for i in keys:\n",
    "        df_curr[i+'_gradient']=(df_curr[i]-df_prev[i])/0.05*7200\n",
    "    return df_curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1132, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_filtered = all_data[all_data['normal_time'] > 10]\n",
    "all_data_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/199 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "features_at_percent = {}\n",
    "\n",
    "# find index of statistics array at certain percent of TL\n",
    "def find_index_at_percent(stats, percent):\n",
    "    left = 0\n",
    "    right = len(stats) - 1\n",
    "    while left < right:\n",
    "        mid = (left + right) // 2\n",
    "        \n",
    "        if stats[mid]['search_time'] == percent:\n",
    "            # Found the first dictionary with target time\n",
    "            while mid > 0 and stats[mid-1]['search_time'] == percent:\n",
    "                mid -= 1\n",
    "            return mid\n",
    "        elif stats[mid]['search_time'] < percent:\n",
    "            left = mid + 1\n",
    "        else:\n",
    "            right = mid - 1\n",
    "\n",
    "    return -1\n",
    "\n",
    "for i in tqdm(range(1,200)):\n",
    "    df_i=[]\n",
    "    for id, problem in all_data_filtered.iterrows():\n",
    "        time_percent = (i / 2) * 7200\n",
    "        index = find_index_at_percent(problem.statistics, time_percent)\n",
    "        p = problem.statistics[index]\n",
    "        # for index, p in enumerate(problem.statistics):\n",
    "        #     if index == i:\n",
    "        new_p = dict(p)\n",
    "        new_p=cleanup(new_p)\n",
    "        if i!=1:\n",
    "            new_p=gradients(df_prev.loc[id], new_p)\n",
    "        new_p['mzn'] = problem['mzn']\n",
    "        new_p['dzn'] = problem['dzn']\n",
    "        new_p['solved_within_time_limit'] = problem['normal_time'] < 7199 * 1000 \\\n",
    "        or np.logical_not(np.isnan(problem['normal_time']))\n",
    "        df_i.append((id, new_p))\n",
    "\n",
    "    df_i = pd.DataFrame([a[1] for a in df_i], index=[a[0] for a in df_i])\n",
    "    df_i=df_i.fillna(value = 0)\n",
    "    if i!=0:   \n",
    "        features_at_percent[i]=df_i\n",
    "    df_prev=df_i\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "done-soon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
